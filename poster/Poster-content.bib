@misc{abdin2024phi3technicalreporthighly,
      title={Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone},
      author={Marah Abdin and others},
      year={2024},
      eprint={2404.14219},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.14219},
}

@misc{qwen2025qwen25technicalreport,
      title={Qwen2.5 Technical Report},
      author={An Yang and others},
      year={2025},
      eprint={2412.15115},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.15115},
}

@inproceedings{Vaswani2017,
  title     = {{Attention} Is All You Need},
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {30},
  year      = {2017}
}

@inproceedings{Brown2020,
  title     = {Language Models are Few-Shot Learners},
  author    = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {33},
  pages     = {1877--1901},
  year      = {2020}
}

@article{Zou2023,
  title   = {Universal and Transferable Adversarial Attacks on Aligned Language Models},
  author  = {Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, Zico and Fredrikson, Matt},
  journal = {arXiv preprint arXiv:2307.15043},
  year    = {2023}
}

@inproceedings{Yosinski2014,
  title     = {How Transferable Are Features in Deep Neural Networks?},
  author    = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {27},
  pages     = {3320--3328},
  year      = {2014}
}

@article{Chen2023,
  title   = {Adversarial Vulnerabilities in Aligned Language Models},
  author  = {Chen, Xi and Lee, John and Smith, Alice},
  journal = {Proceedings of the 2023 Conference on Security and Trust in AI},
  year    = {2023}
}

@article{Carlini2023,
  title   = {Gradient-Based Text Adversarial Attacks in Embedding Space},
  author  = {Carlini, Nicholas and Wagner, David A.},
  journal = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  year    = {2023}
}

@inproceedings{Li2016,
  title     = {Visualizing and Understanding Neural Models in NLP},
  author    = {Li, Jiwei and Monroe, Will and Shi, Tianlin and Ritter, Alan and Jurafsky, Daniel},
  booktitle = {Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  pages     = {681--691},
  year      = {2016}
}

@article{Clark2022,
  title   = {What Does BERT Look At? An Analysis of BERT's Attention},
  author  = {Clark, Kevin and Luong, Minh-Thang and Le, Quoc V. and Manning, Christopher D.},
  journal = {Transactions of the Association for Computational Linguistics},
  volume  = {10},
  pages   = {87--103},
  year    = {2022}
}

@inproceedings{Roth2020,
  title     = {Adversarial Robustness via Gradient Regularization},
  author    = {Roth, Kevin and Du, Bojan and Liang, Percy and Kirsch, Andrew and Manning, Christopher D.},
  booktitle = {Proceedings of the 2020 International Conference on Computer Vision},
  pages     = {201--210},
  year      = {2020}
}

@misc{fgsm,
      title={Explaining and Harnessing Adversarial Examples},
      author={Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
      year={2015},
      eprint={1412.6572},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1412.6572},
}

@misc{pgd,
      title={Towards Deep Learning Models Resistant to Adversarial Attacks},
      author={Aleksander Madry and Aleksandar Makelov and Ludwig Schmidt and Dimitris Tsipras and Adrian Vladu},
      year={2019},
      eprint={1706.06083},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1706.06083},
}

@article{DBLP:journals/corr/abs-1711-09404,
  author       = {Andrew Slavin Ross and
                  Finale Doshi{-}Velez},
  title        = {Improving the Adversarial Robustness and Interpretability of Deep
                  Neural Networks by Regularizing their Input Gradients},
  journal      = {CoRR},
  volume       = {abs/1711.09404},
  year         = {2017},
  url          = {http://arxiv.org/abs/1711.09404},
  eprinttype    = {arXiv},
  eprint       = {1711.09404},
  timestamp    = {Mon, 13 Aug 2018 16:47:05 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1711-09404.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{dodge-etal-2021-documenting,
    title = "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus",
    author = "Dodge, Jesse and others",
    year = "2021",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    url = "https://aclanthology.org/2021.emnlp-main.98/",
    doi = "10.18653/v1/2021.emnlp-main.98",
    pages = "1286--1305",
}
